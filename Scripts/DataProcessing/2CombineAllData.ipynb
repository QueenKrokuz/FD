{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCINnHZAHnma"
   },
   "source": [
    "### Import packages and setup plot parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NJ_hzstDHnmg"
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import re\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Ensure interactive mode enabled/disabled as needed\n",
    "#plt.ion()\n",
    "\n",
    "# Store plot parameters\n",
    "params = {\"ytick.color\" : \"w\",\n",
    "          \"xtick.color\" : \"w\",\n",
    "          \"axes.labelcolor\" : \"w\",\n",
    "          \"axes.edgecolor\" : \"w\"}\n",
    "# Update plot parameters\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9m4kTz3Hnmi"
   },
   "source": [
    "### Load demographic information and species keys, merge together so each individual has a translated Species column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZcRLO3KHnmj"
   },
   "outputs": [],
   "source": [
    "demoinfo = pd.read_csv(\"/home/moonmoon/FD/Native_Pop.csv\")\n",
    "SpKey = pd.read_csv(\"/home/moonmoon/FD/SpeciesKey.csv\")\n",
    "SpKey = SpKey.dropna(axis='columns')\n",
    "demoinfo = pd.merge(demoinfo, SpKey, left_on = 'Species', right_on = \"Key\", how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mVxwL5CWHnmk",
    "outputId": "cb654352-8b56-4950-b4c0-e0ff4369ea55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TROPHEOPS KUMWERA_Cichlid1_10242022_2_1.0\n",
      "TROPHEOPS KUMWERA_Cichlid1_10242022_2_2.0\n",
      "TROPHEOPS KUMWERA_Cichlid1_10242022_2_3.0\n",
      "TROPHEOPS KUMWERA_Cichlid1_10242022_2_4.0\n",
      "TROPHEOPS KUMWERA_Cichlid1_10242022_2_5.0\n",
      "MAYLANDIA FAIAZIBERI MAISON REEF_Cichlid2_01302023_1_1.0\n",
      "MAYLANDIA FAIAZIBERI MAISON REEF_Cichlid2_01302023_1_2.0\n",
      "MAYLANDIA FAIAZIBERI MAISON REEF_Cichlid2_01302023_1_3.0\n",
      "MAYLANDIA FAIAZIBERI MAISON REEF_Cichlid2_01302023_1_4.0\n",
      "MAYLANDIA FAIAZIBERI MAISON REEF_Cichlid2_01302023_1_5.0\n",
      "TROPHEOPS KUMWERA_Cichlid2_01302023_2_1.0\n",
      "TROPHEOPS KUMWERA_Cichlid2_01302023_2_2.0\n",
      "TROPHEOPS KUMWERA_Cichlid2_01302023_2_3.0\n",
      "TROPHEOPS KUMWERA_Cichlid2_01302023_2_4.0\n",
      "TROPHEOPS KUMWERA_Cichlid2_01302023_2_5.0\n",
      "METRIACLIMA \"DAKTARI\" (HAI REEF)_Cichlid2_04192023_2_1.0\n",
      "METRIACLIMA \"DAKTARI\" (HAI REEF)_Cichlid2_04192023_2_2.0\n",
      "METRIACLIMA \"DAKTARI\" (HAI REEF)_Cichlid2_04192023_2_3.0\n",
      "METRIACLIMA \"DAKTARI\" (HAI REEF)_Cichlid2_04192023_2_4.0\n",
      "METRIACLIMA \"DAKTARI\" (HAI REEF)_Cichlid2_04192023_2_5.0\n"
     ]
    }
   ],
   "source": [
    "# Change current working directory\n",
    "os.chdir(\"/home/moonmoon/FD/cut0s/Albertson/Group\")\n",
    "\n",
    "# Create empty dictionary\n",
    "dist = {}\n",
    "\n",
    "# Set static variable\n",
    "FPS = 15\n",
    "\n",
    "# Create empty dataframe\n",
    "demodata = pd.DataFrame()\n",
    "\n",
    "# List files in current working directory\n",
    "list_files = os.listdir(os.getcwd())\n",
    "\n",
    "# Loop through all files in current working directory\n",
    "for file in list_files:\n",
    "    # If file has extension .pkl and has cut0 in the name, execute the following commands\n",
    "    if file.endswith('.pkl') and 'cut0' in file:\n",
    "        # Split unnecessary file information off of filename\n",
    "        namestr = re.split(\"-|crop|(?=\\\\d{2}_)|\\\\.\", file)\n",
    "        # Add '20' to front of year\n",
    "        namestr = (f'{namestr[2]}20{namestr[3]}')\n",
    "        # Check filename\n",
    "        #print(namestr)\n",
    "        # Filter demographic information by filename\n",
    "        filedemo = demoinfo.loc[demoinfo['FileName'] == namestr].copy()\n",
    "        # Find mean size of all fish in given file\n",
    "        temp = filedemo['Size (inches)'].mean()\n",
    "        # Override measured sizes by average size for body lengths calculation\n",
    "        filedemo['Size (inches)'] = temp\n",
    "        # Drop duplicates (all numbers should match now)\n",
    "        filedemo = filedemo.drop_duplicates()\n",
    "        # Check demographic information is a single row\n",
    "        #print(filedemo)\n",
    "        # Append demographic information to dataframe\n",
    "        demodata = pd.concat([demodata, filedemo], axis = 0)\n",
    "        # Open current pkl+ cut0 file for reading\n",
    "        myfile = open(file, \"rb\")\n",
    "        # Check which file is being accessed\n",
    "        #print(myfile)\n",
    "        # Load pkl+ file into temporary pandas dataframe with following column names\n",
    "        temp = pd.DataFrame(pkl.load(myfile), columns = ['x1', 'y1', 'x2', 'y2', 'id', 'frame'])\n",
    "        # Check content and dimensions of file\n",
    "        #print(f'{temp} by {len(temp)})\n",
    "        # Close current file connection\n",
    "        myfile.close()\n",
    "        # Group temporary dataframe by ID to facilitate future filtering of null detections\n",
    "        grouped = temp.groupby('id')\n",
    "        # Check content and dimensions of grouped data\n",
    "        #print(f'{grouped} by {len(grouped)}')\n",
    "        # Loop through grouped data storing name and group content, then execute the following commands\n",
    "        key = filedemo['Species_y'].iloc[0]\n",
    "        key = key.upper()\n",
    "        #print(key)\n",
    "        for name, group in grouped:\n",
    "            # If key/name string ends with ID 0.0, execute the following command\n",
    "            if name == 0:\n",
    "                # Skip this iteration\n",
    "                continue\n",
    "            # If valid ID, execute the following commands\n",
    "            else:\n",
    "                group = group.reset_index()\n",
    "\n",
    "                # Find midpoint between x1 and x2, store in x variable\n",
    "                group['x'] = (group['x1'] + group['x2']) / 2\n",
    "                # Find midpoint between y1 and y2, store in y variable\n",
    "                group['y'] = (group['y1'] + group['y2']) / 2\n",
    "\n",
    "                # Convert to artifical lng [0-1]\n",
    "                group['x'] = MinMaxScaler(feature_range=(0, 1)).fit_transform(pd.DataFrame(group['x']))\n",
    "                # Convert to artifical lat [0-1]\n",
    "                group['y'] = MinMaxScaler(feature_range=(0, 0.5)).fit_transform(pd.DataFrame(group['y']))\n",
    "\n",
    "                # Divide frame series by frames per second, store as seconds\n",
    "                seconds = group['frame']/FPS\n",
    "                # Create proxy date (real date unnecessary)\n",
    "                dateproxy = datetime(2024, 8, 25, 0, 0, 0)\n",
    "                # Check static variable content\n",
    "                #print(dateproxy)\n",
    "\n",
    "                # Create time proxy (real time unnecessary, may implement in future)\n",
    "                timeproxy = pd.to_timedelta(seconds, unit = 's')\n",
    "                # Check static variable content\n",
    "                #print(timeproxy)\n",
    "\n",
    "                # Merge date and time proxies for final proxy to use in MovingPandas analyses\n",
    "                finalproxy = dateproxy + timeproxy\n",
    "                # Check static variable content\n",
    "                #print(finalproxy)\n",
    "\n",
    "                # Assign converted values to original value\n",
    "                group['frame'] = finalproxy\n",
    "\n",
    "                print(f'{key}_{namestr}_{name}')\n",
    "                # Store filtered and pared data into new dictionary with key/file name as the key\n",
    "                dist[f'{key}_{namestr}_{name}'] = pd.concat([group['frame'], group['x'], group['y'], group['id']], axis = 1)\n",
    "# Ad hoc sort dist dictionary to order Species names/graphs\n",
    "dist = dict(sorted(dist.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTeDv1NoHnml"
   },
   "source": [
    "### Delete extraneous variables to prevent crashing when additional data is loaded (janky troubleshooting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AuEaAmXrHnmm"
   },
   "outputs": [],
   "source": [
    "del dateproxy, demoinfo, file, filedemo, finalproxy, group, grouped, key, list_files, myfile, name, namestr, seconds, SpKey, temp, timeproxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prfS3aLCHnmn"
   },
   "source": [
    "### Load Cut0s into dictionary with species and file names as keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eXagm3MhHnmn"
   },
   "outputs": [],
   "source": [
    "# Change current working directory\n",
    "os.chdir(\"/home/moonmoon/FD/cut0s/Keene/Group\")\n",
    "\n",
    "# Create empty dictionary\n",
    "Kdist = {}\n",
    "\n",
    "# List files in current working directory\n",
    "list_files = os.listdir(os.getcwd())\n",
    "\n",
    "# Loop through all files in current working directory\n",
    "for file in list_files:\n",
    "    # If file has extension .pkl and has cut0 in the name, execute the following commands\n",
    "    if file.endswith('.pkl') and 'cut0' in file:\n",
    "        # Open current pkl+ cut0 file for reading\n",
    "        myfile = open(file, \"rb\")\n",
    "        # Check which file is being accessed\n",
    "        #print(myfile)\n",
    "        # Load pkl+ file into temporary pandas dataframe with following column names\n",
    "        temp = pd.DataFrame(pkl.load(myfile), columns = ['x1', 'y1', 'x2', 'y2', 'id', 'frame'])\n",
    "        # Check content and dimensions of file\n",
    "        #print(f'{temp} by {len(temp)})\n",
    "        # Close current file connection\n",
    "        myfile.close()\n",
    "        # Group temporary dataframe by ID to facilitate future filtering of null detections\n",
    "        grouped = temp.groupby('id')\n",
    "        # Check content and dimensions of grouped data\n",
    "        #print(f'{grouped} by {len(grouped)})\n",
    "        # Loop through grouped data storing name and group content, then execute the following commands\n",
    "        for name, group in grouped:\n",
    "            # Create namestring for alteration, by removing extension from file name and adding ID\n",
    "            namestr = f'{os.path.splitext(file)[0]}_{name}'\n",
    "            # Convert all strings to uppercase, to standardize capitalization\n",
    "            namestr = namestr.upper()\n",
    "            # Split at the first occurence of an underscore character, store list in namestr variable\n",
    "            namestr = namestr.split('_', maxsplit = 1)\n",
    "            # Check content of namestr variable and group\n",
    "            #print(f'{namestr[1]} in {group}')\n",
    "\n",
    "            # If key/name string ends with ID 0.0, execute the following command\n",
    "            if name == 0:\n",
    "                # Skip this iteration\n",
    "                continue\n",
    "            # If valid ID, execute the following commands\n",
    "            else:\n",
    "                group = group.reset_index()\n",
    "\n",
    "                # Find midpoint between x1 and x2, store in x variable\n",
    "                group['x'] = (group['x1'] + group['x2']) / 2\n",
    "                # Find midpoint between y1 and y2, store in y variable\n",
    "                group['y'] = (group['y1'] + group['y2']) / 2\n",
    "\n",
    "                # Convert to artifical lng [0-1]\n",
    "                group['x'] = MinMaxScaler(feature_range=(0, 1)).fit_transform(pd.DataFrame(group['x']))\n",
    "                # Convert to artifical lat [0-1]\n",
    "                group['y'] = MinMaxScaler(feature_range=(0, 0.5)).fit_transform(pd.DataFrame(group['y']))\n",
    "\n",
    "                # Divide frame series by frames per second, store as seconds\n",
    "                seconds = group['frame']/FPS\n",
    "                # Create proxy date (real date unnecessary)\n",
    "                dateproxy = datetime(2024, 8, 25, 0, 0, 0)\n",
    "                # Check static variable content\n",
    "                #print(dateproxy)\n",
    "\n",
    "                # Create time proxy (real time unnecessary, may implement in future)\n",
    "                timeproxy = pd.to_timedelta(seconds, unit = 's')\n",
    "                # Check static variable content\n",
    "                #print(timeproxy)\n",
    "\n",
    "                # Merge date and time proxies for final proxy to use in MovingPandas analyses\n",
    "                finalproxy = dateproxy + timeproxy\n",
    "                # Check static variable content\n",
    "                #print(finalproxy)\n",
    "\n",
    "                # Assign converted values to original value\n",
    "                group['frame'] = finalproxy\n",
    "\n",
    "                # Store filtered and pared data into new dictionary with key/file name as the key\n",
    "                Kdist[f'{namestr[1]}'] = pd.concat([group['frame'], group['x'], group['y'], group['id']], axis = 1)\n",
    "                # Check contents of dictionary given key\n",
    "                #print(Kdist[f'{key}'])\n",
    "\n",
    "# Ad hoc sort dist dictionary to order Species names/graphs\n",
    "Kdist = dict(sorted(Kdist.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3htczqJXHnmo"
   },
   "source": [
    "### Delete extraneous variables to prevent crashing when additional data is loaded (janky troubleshooting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M7X-r_rBHnmo"
   },
   "outputs": [],
   "source": [
    "del dateproxy, file, finalproxy, FPS, group, grouped, list_files, myfile, name, namestr, seconds, temp, timeproxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "toLmRtvXHnmp"
   },
   "source": [
    "### Extract dictionary keys, combine dictionaries, create species list from dictionary keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "krV7dnPIHnmp"
   },
   "outputs": [],
   "source": [
    "DictKeys = list(Kdist.keys()) + list(dist.keys())\n",
    "\n",
    "sorted_dist = {**Kdist, **dist}\n",
    "sorted_dist = dict(sorted(sorted_dist.items()))\n",
    "\n",
    "SpeciesList = []\n",
    "\n",
    "for name in DictKeys:\n",
    "    temp = name.split(\"_\", maxsplit = 1)\n",
    "    SpeciesList.append(temp[0])\n",
    "\n",
    "SpeciesList = np.unique(SpeciesList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CZYVLgI-Hnmq"
   },
   "outputs": [],
   "source": [
    "del DictKeys, dist, Kdist, name, temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80VyGCcwHnmq"
   },
   "outputs": [],
   "source": [
    "# Open cut0 (all cuts) pickle for writing, assign name by folder in loop\n",
    "myfile = open(f'/home/moonmoon/FD/_Output/sorted_dist.pkl', \"wb\")\n",
    "# Dump pickle data into file and seal up for sleepies\n",
    "pkl.dump(sorted_dist, myfile)\n",
    "# Close file connection\n",
    "myfile.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "FD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
